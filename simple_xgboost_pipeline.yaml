# PIPELINE DEFINITION
# Name: simple-xgboost-pipeline
# Description: A simple automated XGBoost training pipeline
components:
  comp-evaluate-model:
    executorLabel: exec-evaluate-model
  comp-train-xgboost:
    executorLabel: exec-train-xgboost
deploymentSpec:
  executors:
    exec-evaluate-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluate_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet     --no-warn-script-location 'kfp==2.0.1'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef evaluate_model():\n    \"\"\"Model evaluation component\"\"\"\
          \n    import xgboost as xgb\n    import numpy as np\n    import matplotlib.pyplot\
          \ as plt\n    import os\n\n    print(\"\U0001F4C8 Evaluating model...\"\
          )\n\n    # Load model\n    model = xgb.XGBRegressor()\n    model.load_model('/tmp/model/xgboost_model.json')\n\
          \n    # Generate test data\n    np.random.seed(123)\n    X_test = np.random.randn(100,\
          \ 5)\n    y_test = np.dot(X_test, np.random.randn(5) * 0.5) + np.random.normal(0,\
          \ 0.1, 100)\n\n    # Make predictions\n    y_pred = model.predict(X_test)\n\
          \n    # Create evaluation plot\n    os.makedirs('/tmp/evaluation', exist_ok=True)\n\
          \    plt.figure(figsize=(8, 6))\n    plt.scatter(y_test, y_pred, alpha=0.6)\n\
          \    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],\
          \ 'r--', lw=2)\n    plt.xlabel('Actual Values')\n    plt.ylabel('Predicted\
          \ Values')\n    plt.title('XGBoost Model: Actual vs Predicted')\n    plt.tight_layout()\n\
          \    plt.savefig('/tmp/evaluation/predictions.png', dpi=300, bbox_inches='tight')\n\
          \    plt.close()\n\n    print(\"\u2705 Model evaluation completed!\")\n\
          \    return \"Evaluation plots saved\"\n\n"
        image: python:3.7
    exec-train-xgboost:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_xgboost
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet     --no-warn-script-location 'kfp==2.0.1'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_xgboost():\n    \"\"\"Simple XGBoost training component\"\
          \"\"\n    import numpy as np\n    import pandas as pd\n    import xgboost\
          \ as xgb\n    from sklearn.model_selection import train_test_split\n   \
          \ from sklearn.metrics import r2_score\n    import joblib\n    import os\n\
          \n    print(\"\U0001F680 Starting XGBoost training...\")\n\n    # Generate\
          \ synthetic data\n    np.random.seed(42)\n    n_samples = 1000\n    n_features\
          \ = 5\n\n    X = np.random.randn(n_samples, n_features)\n    coefficients\
          \ = np.random.randn(n_features) * 0.5\n    y = np.dot(X, coefficients) +\
          \ np.random.normal(0, 0.1, n_samples)\n\n    # Split data\n    X_train,\
          \ X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2,\
          \ random_state=42\n    )\n\n    # Train model\n    model = xgb.XGBRegressor(n_estimators=50,\
          \ max_depth=4, random_state=42)\n    model.fit(X_train, y_train)\n\n   \
          \ # Evaluate\n    y_pred = model.predict(X_test)\n    r2 = r2_score(y_test,\
          \ y_pred)\n\n    print(f\"\u2705 Model trained successfully!\")\n    print(f\"\
          \U0001F4CA R\xB2 Score: {r2:.4f}\")\n\n    # Save model\n    os.makedirs('/tmp/model',\
          \ exist_ok=True)\n    model.save_model('/tmp/model/xgboost_model.json')\n\
          \n    return f\"Model saved with R\xB2: {r2:.4f}\"\n\n"
        image: python:3.7
pipelineInfo:
  description: A simple automated XGBoost training pipeline
  name: simple-xgboost-pipeline
root:
  dag:
    tasks:
      evaluate-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-evaluate-model
        dependentTasks:
        - train-xgboost
        taskInfo:
          name: evaluate-model
      train-xgboost:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-xgboost
        taskInfo:
          name: train-xgboost
schemaVersion: 2.1.0
sdkVersion: kfp-2.0.1
